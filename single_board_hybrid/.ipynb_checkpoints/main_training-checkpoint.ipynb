{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name: GeForce RTX 2080 Ti, gpu_id: 0\n",
      "cuda\n",
      "pytorch version =  1.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "# visualization \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "device = torch.device(\"cpu\"); gpu_id = -1 # select CPU\n",
    "\n",
    "gpu_id = '0' # select a single GPU  \n",
    "#gpu_id = '2,3' # select multiple GPUs  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n",
    "    \n",
    "print(device)\n",
    "print('pytorch version = ',torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "class TransEncoderNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder network based on self-attention transformer\n",
    "    Inputs :  \n",
    "      h of size      (bsz, nb_nodes, dim_emb)    batch of input cities\n",
    "    Outputs :  \n",
    "      h of size      (bsz, nb_nodes, dim_emb)    batch of encoded cities\n",
    "      score of size  (bsz, nb_nodes, nb_nodes+1) batch of attention scores\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n",
    "        super(TransEncoderNet, self).__init__()\n",
    "        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n",
    "        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n",
    "        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n",
    "        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n",
    "        if batchnorm:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "        else:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_heads = nb_heads\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "    def forward(self, h):      \n",
    "        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n",
    "        h = h.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)  \n",
    "        # L layers\n",
    "        for i in range(self.nb_layers):\n",
    "            h_rc = h # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n",
    "            h, score = self.MHA_layers[i](h, h, h) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n",
    "            # add residual connection\n",
    "            \n",
    "            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n",
    "                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = self.norm1_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                h = self.norm1_layers[i](h)       # size(h)=(nb_nodes, bsz, dim_emb) \n",
    "            # feedforward\n",
    "            h_rc = h # residual connection\n",
    "            h = self.linear2_layers[i](torch.relu(self.linear1_layers[i](h)))\n",
    "            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = self.norm2_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                h = self.norm2_layers[i](h) # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "        # Transpose h\n",
    "        h = h.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n",
    "        return h, score\n",
    "    \n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(Attention, self).__init__()\n",
    "        self.size = 0\n",
    "        self.batch_size = 0\n",
    "        self.dim = n_hidden\n",
    "        \n",
    "        v  = torch.FloatTensor(n_hidden)\n",
    "        self.v  = nn.Parameter(v)\n",
    "        self.v.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "        \n",
    "        # parameters for pointer attention\n",
    "        self.Wref = nn.Linear(n_hidden, n_hidden)\n",
    "        self.Wq = nn.Linear(n_hidden, n_hidden)\n",
    "    \n",
    "    \n",
    "    def forward(self, q, ref):       # query and reference\n",
    "        self.batch_size = q.size(0)\n",
    "        self.size = int(ref.size(0) / self.batch_size)\n",
    "        q = self.Wq(q)     # (B, dim)\n",
    "        ref = self.Wref(ref)\n",
    "        ref = ref.view(self.batch_size, self.size, self.dim)  # (B, size, dim)\n",
    "        \n",
    "        q_ex = q.unsqueeze(1).repeat(1, self.size, 1) # (B, size, dim)\n",
    "        # v_view: (B, dim, 1)\n",
    "        v_view = self.v.unsqueeze(0).expand(self.batch_size, self.dim).unsqueeze(2)\n",
    "        \n",
    "        # (B, size, dim) * (B, dim, 1)\n",
    "        u = torch.bmm(torch.tanh(q_ex + ref), v_view).squeeze(2)\n",
    "        \n",
    "        return u, ref\n",
    "    \n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # parameters for input gate\n",
    "        self.Wxi = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whi = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wci = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "        \n",
    "        # parameters for forget gate\n",
    "        self.Wxf = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whf = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wcf = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "        \n",
    "        # parameters for cell gate\n",
    "        self.Wxc = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whc = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        \n",
    "        # parameters for forget gate\n",
    "        self.Wxo = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Who = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wco = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, h, c):       # query and reference\n",
    "        \n",
    "        # input gate\n",
    "        i = torch.sigmoid(self.Wxi(x) + self.Whi(h) + self.wci(c))\n",
    "        # forget gate\n",
    "        f = torch.sigmoid(self.Wxf(x) + self.Whf(h) + self.wcf(c))\n",
    "        # cell gate\n",
    "        c = f * c + i * torch.tanh(self.Wxc(x) + self.Whc(h))\n",
    "        # output gate\n",
    "        o = torch.sigmoid(self.Wxo(x) + self.Who(h) + self.wco(c))\n",
    "        \n",
    "        h = o * torch.tanh(c)\n",
    "        \n",
    "        return h, c\n",
    "\n",
    "class HPN(nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden):\n",
    "\n",
    "        super(HPN, self).__init__()\n",
    "        self.city_size = 0\n",
    "        self.batch_size = 0\n",
    "        self.dim = n_hidden\n",
    "        \n",
    "        # lstm for first turn\n",
    "        #self.lstm0 = nn.LSTM(n_hidden, n_hidden)\n",
    "        \n",
    "        # pointer layer\n",
    "        self.pointer = Attention(n_hidden)\n",
    "        self.TransPointer = Attention(n_hidden)\n",
    "        \n",
    "        # lstm encoder\n",
    "        self.encoder = LSTM(n_hidden)\n",
    "        \n",
    "        # trainable first hidden input\n",
    "        h0 = torch.FloatTensor(n_hidden)\n",
    "        c0 = torch.FloatTensor(n_hidden)\n",
    "        # trainable latent variable coefficient\n",
    "        print('here') \n",
    "        alpha = torch.ones(1).cuda()       \n",
    "        self.h0 = nn.Parameter(h0)\n",
    "        self.c0 = nn.Parameter(c0)\n",
    "        \n",
    "        self.alpha = nn.Parameter(alpha)\n",
    "        self.h0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "        self.c0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "        \n",
    "        r1 = torch.ones(1)\n",
    "        r2 = torch.ones(1)\n",
    "        r3 = torch.ones(1)\n",
    "        self.r1 = nn.Parameter(r1)\n",
    "        self.r2 = nn.Parameter(r2)\n",
    "        self.r3 = nn.Parameter(r3)\n",
    "        \n",
    "        # embedding\n",
    "        self.embedding_x = nn.Linear(n_feature, n_hidden)\n",
    "        self.embedding_all = nn.Linear(n_feature, n_hidden)\n",
    "        self.Transembedding_all = TransEncoderNet(6, 128, 8, 512, batchnorm=True)#6,128,8,512\n",
    "        \n",
    "        # vector to start decoding \n",
    "        self.start_placeholder = nn.Parameter(torch.randn(n_hidden))\n",
    "        \n",
    "        # weights for GNN\n",
    "        self.W1 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.W2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.W3 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        # aggregation function for GNN\n",
    "        self.agg_1 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.agg_2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.agg_3 = nn.Linear(n_hidden, n_hidden)\n",
    "    \n",
    "    \n",
    "    def forward(self,context,Transcontext, x, X_all, mask, h=None, c=None, latent=None):\n",
    "        '''\n",
    "        Inputs (B: batch size, size: city size, dim: hidden dimension)\n",
    "        \n",
    "        x: current city coordinate (B, 2)\n",
    "        X_all: all cities' cooridnates (B, size, 2)\n",
    "        mask: mask visited cities\n",
    "        h: hidden variable (B, dim)\n",
    "        c: cell gate (B, dim)\n",
    "        latent: latent pointer vector from previous layer (B, size, dim)\n",
    "        \n",
    "        Outputs\n",
    "        \n",
    "        softmax: probability distribution of next city (B, size)\n",
    "        h: hidden variable (B, dim)\n",
    "        c: cell gate (B, dim)\n",
    "        latent_u: latent pointer vector for next layer\n",
    "        '''\n",
    "        \n",
    "        self.batch_size = X_all.size(0)\n",
    "        self.city_size = X_all.size(1)\n",
    "        \n",
    "        # Check if this the first iteration loop\n",
    "        if h is None or c is None:\n",
    "            x          = self.start_placeholder    \n",
    "            context = self.embedding_all(X_all)\n",
    "            Transcontext,_ = self.Transembedding_all(context)\n",
    "            \n",
    "            # =============================\n",
    "            # graph neural network encoder\n",
    "            # =============================\n",
    "\n",
    "            # (B, size, dim)\n",
    "            context = context.reshape(-1, self.dim)\n",
    "            Transcontext = Transcontext.reshape(-1, self.dim)\n",
    "\n",
    "            context = self.r1 * self.W1(context)\\\n",
    "                + (1-self.r1) * F.relu(self.agg_1(context/(self.city_size-1)))\n",
    "\n",
    "            context = self.r2 * self.W2(context)\\\n",
    "                + (1-self.r2) * F.relu(self.agg_2(context/(self.city_size-1)))\n",
    "\n",
    "            context = self.r3 * self.W3(context)\\\n",
    "                + (1-self.r3) * F.relu(self.agg_3(context/(self.city_size-1)))\n",
    "            h0 = self.h0.unsqueeze(0).expand(self.batch_size, self.dim)\n",
    "            c0 = self.c0.unsqueeze(0).expand(self.batch_size, self.dim)\n",
    "\n",
    "            h0 = h0.unsqueeze(0).contiguous()\n",
    "            c0 = c0.unsqueeze(0).contiguous()\n",
    "            \n",
    "            # let h0, c0 be the hidden variable of first turn\n",
    "            h = h0.squeeze(0)\n",
    "            c = c0.squeeze(0)\n",
    "        else:\n",
    "            x          = self.embedding_x(x)\n",
    "        # LSTM encoder\n",
    "        h, c = self.encoder(x, h, c)\n",
    "        # query vector\n",
    "        q = h\n",
    "        # pointer\n",
    "        u1, _ = self.pointer(q, context)\n",
    "        u2 ,_ = self.TransPointer(q,Transcontext)\n",
    "        # Avg Agg between the two attention vectors\n",
    "        u = torch.maximum(u1,u2)\n",
    "        latent_u = u.clone()\n",
    "        u = 10 * torch.tanh(u) + mask\n",
    "        return context,Transcontext,F.softmax(u, dim=1), h, c, latent_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# daniel rectangle feature handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This part I designed the rectangle-characterized TSP, that means for every step the agent walk through a corner,\n",
    "then he travel through the whole rectangle using zig-zag, finally he ends up at one of the rest corners of \n",
    "the rextangle, so, it equals the agent walk through three points at one step, in practice, I add three points into \n",
    "mask to make them unselectable.\n",
    "'''\n",
    "def euler_distance(point_1,point_2):\n",
    "    return torch.sum((point_1 - point_2) ** 2, dim=1) ** 0.5\n",
    "def mintime_distance(point_1,point_2):\n",
    "    dis = (point_1 - point_2)**2\n",
    "    reward = torch.maximum(dis[:,0],dis[:,1])**0.5\n",
    "    return reward\n",
    "def calculate_vector(item_1,item_2):\n",
    "    slope_temp = item_1 - item_2\n",
    "    return slope_temp\n",
    "def rectangle_process(b_temp,f_temp,idx,Y,Y0,mask,k,B,barrier_points):\n",
    "    Y1 = Y[zero_to_bsz, idx.data].clone()\n",
    "    # start to detect the barrier by calculate (Y1-Y0) slope\n",
    "    if Y0 != None:\n",
    "        vector = calculate_vector(Y1,Y0) # tensor of 256 points - tensor of 256 points\n",
    "        euler = euler_distance(Y1,Y0)\n",
    "        vector_barrier = []\n",
    "        euler_barrier = []\n",
    "    # making a tensor list of slope value and distance\n",
    "        for i in range(len(barrier_points[0])):\n",
    "            barriers = barrier_points[:,i] \n",
    "            vector_temp = calculate_vector(barriers,Y0)\n",
    "            vector_barrier.append(vector_temp)\n",
    "            euler_barrier.append(euler_distance(barriers,Y0))\n",
    "    rectangle_inf = idx/4\n",
    "    feature_table = f_temp.outcorner_getout(rectangle_inf,B)\n",
    "    feature_table = torch.Tensor(feature_table).type(torch.long)\n",
    "    Y_corner = Y[zero_to_bsz, feature_table[:,0].data].clone()\n",
    "    if k ==0:\n",
    "        reward = 0\n",
    "    if k > 0:\n",
    "        reward = euler_distance(Y1,Y0)\n",
    "        reward += euler_distance(Y_corner,Y1)\n",
    "        reward += b_temp.barrier_detect(vector_barrier, euler_barrier, vector, euler)\n",
    "    \n",
    "    mask[zero_to_bsz, idx.data] += -np.inf\n",
    "    mask[zero_to_bsz, feature_table[:,0].data] += -np.inf\n",
    "    mask[zero_to_bsz, feature_table[:,1].data] += -np.inf    \n",
    "    mask[zero_to_bsz, feature_table[:,2].data] += -np.inf \n",
    "    return reward, Y_corner, Y_corner\n",
    "def rectangle_process_actor(b_temp,f_temp,idx,Y,Y0,mask,k,B,i,path_gazebo,barrier_points):\n",
    "    Y1 = Y[zero_to_bsz, idx.data].clone()\n",
    "    if Y0 != None:\n",
    "        vector = calculate_vector(Y1,Y0) # tensor of 256 points - tensor of 256 points\n",
    "        euler = euler_distance(Y1,Y0)\n",
    "        vector_barrier = []\n",
    "        euler_barrier = []\n",
    "        for i in range(len(barrier_points[0])):\n",
    "            barriers = barrier_points[:,i] \n",
    "            vector_temp = calculate_vector(barriers,Y0)\n",
    "            vector_barrier.append(vector_temp)\n",
    "            euler_barrier.append(euler_distance(barriers,Y0))\n",
    "    rectangle_inf = idx/4\n",
    "    feature_table = f_temp.outcorner_getout(rectangle_inf,B)\n",
    "    feature_table = torch.Tensor(feature_table).type(torch.long)\n",
    "    Y_corner = Y[zero_to_bsz, feature_table[:,0].data].clone()\n",
    "    if i % 50 == 0:\n",
    "        path_gazebo.append([idx.data[0].tolist(),feature_table[:,0].data[0].tolist()])\n",
    "    if k ==0:\n",
    "        reward = 0\n",
    "    if k > 0:\n",
    "        reward = euler_distance(Y1,Y0)\n",
    "        reward += euler_distance(Y_corner,Y1) \n",
    "        reward += b_temp.barrier_detect(vector_barrier, euler_barrier, vector, euler)\n",
    "    mask[zero_to_bsz, idx.data] += -np.inf\n",
    "    mask[zero_to_bsz, feature_table[:,0].data] += -np.inf\n",
    "    mask[zero_to_bsz, feature_table[:,1].data ] += -np.inf    \n",
    "    mask[zero_to_bsz, feature_table[:,2].data ] += -np.inf \n",
    "    return reward, Y_corner, Y_corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "prepare to train\n",
      "======================\n",
      "Hyper parameters:\n",
      "learning rate 0.0001\n",
      "batch size 256\n",
      "steps 2500\n",
      "epoch 100\n",
      "======================\n",
      "here\n",
      "here\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-331248794a8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m              \u001b[0;31m#prepare for the back propagation of pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrectangle_process_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_temp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath_gazebo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbarrier_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mR\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mlogprobs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzero_to_bsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTINY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b7d944c502f3>\u001b[0m in \u001b[0;36mrectangle_process_actor\u001b[0;34m(b_temp, f_temp, idx, Y, Y0, mask, k, B, i, path_gazebo, barrier_points)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuler_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0meuler_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_corner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mb_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarrier_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_barrier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuler_barrier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzero_to_bsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzero_to_bsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/single_board_main/single_board/single_board_hybrid/listofpathpoint.py\u001b[0m in \u001b[0;36mbarrier_detect\u001b[0;34m(self, vector_barrier, euler_barrier, vector, euler)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meuler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_barrier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mtemp_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_barrier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# load four points of an object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_barrier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mtemp_euler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuler_barrier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "from torch.distributions.categorical import Categorical\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook\n",
    "####### my own import file ##########\n",
    "from listofpathpoint import input_handler\n",
    "import cnc_input\n",
    "#from hybrid_models import HPN\n",
    "####### my own import file ##########\n",
    "'''\n",
    "so, the models we have are TransEncoderNet,\n",
    "                            Attention\n",
    "                            LSTM\n",
    "                            HPN\n",
    "each one have initial parameters and the forward part, \n",
    "once we have the forward part, the back propagation will \n",
    "finished automatically by pytorch  \n",
    "'''\n",
    "size = 136\n",
    "TOL = 1e-3\n",
    "TINY = 1e-15\n",
    "learning_rate = 1e-4   # learning rate\n",
    "B = 256             # batch size\n",
    "B_valLoop = 20\n",
    "steps = 2500\n",
    "n_epoch = 100       # epochs\n",
    "size_rec = int(size/4)\n",
    "\n",
    "print('======================')\n",
    "print('prepare to train')\n",
    "print('======================')\n",
    "print('Hyper parameters:')\n",
    "print('learning rate', learning_rate)\n",
    "print('batch size', B)\n",
    "print('steps', steps)\n",
    "print('epoch', n_epoch)\n",
    "print('======================')\n",
    "\n",
    "'''\n",
    "instantiate a training network and a baseline network\n",
    "'''\n",
    "temp = input_handler('mother_board.json')\n",
    "barrier = input_handler('barrier.json')\n",
    "'''\n",
    "X_val consisted by 'list of list of list'\n",
    "'rectangle list' 'channel list' 'point xy list' respectively\n",
    "'''\n",
    "try:\n",
    "    del Actor  # remove existing model\n",
    "    del Critic # remove existing model\n",
    "except:\n",
    "    pass\n",
    "Actor = HPN(n_feature = 2, n_hidden = 128)\n",
    "Critic = HPN(n_feature = 2, n_hidden = 128)\n",
    "optimizer = optim.Adam(Actor.parameters(), lr=learning_rate)\n",
    "\n",
    "# Putting Critic model on the eval mode\n",
    "Actor = Actor.to(device)\n",
    "Critic = Critic.to(device)\n",
    "Critic.eval()\n",
    "\n",
    "epoch_ckpt = 0\n",
    "tot_time_ckpt = 0\n",
    "\n",
    "val_mean = []\n",
    "val_std = []\n",
    "\n",
    "plot_performance_train = []\n",
    "plot_performance_baseline = []\n",
    "# recording the result of the resent epoch makes it available for future\n",
    "#*********************# Uncomment these lines to load the previous check point\n",
    "\"\"\"\n",
    "checkpoint_file = \"checkpoint/checkpoint_21-12-01--17-19-54-n136-gpu0.pkl\"\n",
    "checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "epoch_ckpt = checkpoint['epoch'] + 1\n",
    "tot_time_ckpt = checkpoint['tot_time']\n",
    "plot_performance_train = checkpoint['plot_performance_train']\n",
    "plot_performance_baseline = checkpoint['plot_performance_baseline']\n",
    "Critic.load_state_dict(checkpoint['model_baseline'])\n",
    "Actor.load_state_dict(checkpoint['model_train'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "print('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\n",
    "\n",
    "\"\"\"\n",
    "#***********************# Uncomment these lines to load the previous check point\n",
    "\n",
    "# Main training loop\n",
    "# The core training concept mainly upon Sampling from the actor\n",
    "# then taking the greedy action from the critic\n",
    "\n",
    "\n",
    "start_training_time = time.time()\n",
    "time_stamp = datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\") # Load the time stamp\n",
    "\n",
    "C = 0       # baseline => the object which the actor can compare\n",
    "R = 0       # reward\n",
    "\n",
    "zero_to_bsz = torch.arange(B, device = device) # a list contains 0 to (batch size -1)\n",
    "\n",
    "for epoch in range(0, n_epoch):\n",
    "    \n",
    "    # re-start training with saved checkpoint\n",
    "    epoch += epoch_ckpt # adding the number of the former epochs\n",
    "    # Train the model for one epoch\n",
    "    start = time.time() # record the starting time\n",
    "    Actor.train() \n",
    "    X_temp = temp.every_point()\n",
    "    X_temp = torch.FloatTensor(X_temp)\n",
    "    f_temp = input_handler('mother_board.json')\n",
    "    b_temp = input_handler('barrier.json')\n",
    "    X = X_temp.repeat(B,1,1)\n",
    "    X = X.cuda()\n",
    "    barrier_temp = barrier.every_point()#left up, right up, right down, left down\n",
    "    barrier_temp = torch.FloatTensor(barrier_temp)\n",
    "    barrier_points = barrier_temp.repeat(B,1,1)\n",
    "    barrier_points = barrier_points.cuda()\n",
    "    path_gazebo = []\n",
    "    \n",
    "    for i in range(1, steps+1): # 1 ~ 2500 steps\n",
    "        mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "        R = 0\n",
    "        logprobs = 0\n",
    "        reward = 0\n",
    "        Y = X.view(B,size,2)\n",
    "        x = torch.zeros(B,2) #Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None        #set Y_ini to the out corner\n",
    "        Transcontext = None\n",
    "        Y0 = None\n",
    "        # Actor Sampling phase\n",
    "        for k in range(size_rec):\n",
    "            context, Transcontext, output, h, c, _ = Actor(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n",
    "            sampler = torch.distributions.Categorical(output)\n",
    "            idx = sampler.sample()\n",
    "             #prepare for the back propagation of pytorch\n",
    "            reward, Y0,x = rectangle_process_actor(b_temp,f_temp, idx,Y,Y0,mask,k,B,i,path_gazebo,barrier_points)\n",
    "            R += reward\n",
    "            logprobs += torch.log(output[zero_to_bsz, idx.data] + TINY)\n",
    "            ##mask[zero_to_bsz, idx.data] += -np.inf\n",
    "# critic baseline phase, use the baseline to compute the actual reward of agent at that time\n",
    "        mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "        C = 0\n",
    "        baseline = 0\n",
    "        Y = X.view(B,size,2)\n",
    "        x = torch.zeros(B,2)#Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None\n",
    "        Transcontext = None\n",
    "        C0 = None\n",
    "        # compute tours for baseline without grad \"Cause we want to fix the weights for the critic\"\n",
    "        with torch.no_grad():\n",
    "            for k in range(size_rec):      \n",
    "                context, Transcontext, output, h, c, _ = Critic(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n",
    "                idx = torch.argmax(output, dim=1) # ----> greedy baseline critic\n",
    "                # prepare for the back propagation of pytorch\n",
    "                baseline, C0,x = rectangle_process(b_temp,f_temp,idx,Y,C0, mask,k,B)\n",
    "                C += baseline\n",
    "        ###################\n",
    "        # Loss and backprop handling \n",
    "        ###################\n",
    "        \n",
    "        loss = torch.mean((R - C) * logprobs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(\"epoch:{}, batch:{}/{}, reward:{}\".format(epoch, i, steps, R.mean().item()))\n",
    "        if i % 50 == 0:\n",
    "            print(\"record the last path to gazebo for showing up\")\n",
    "            #starting to show the path on simulated enviroment of cnc_machine \n",
    "            the_resent_path = temp.zig_zag_path(path_gazebo)\n",
    "            data = {'path':the_resent_path}\n",
    "            data_1 = {'corners':path_gazebo}\n",
    "            pathpoints_dir = os.path.join(\"pathpoints\")\n",
    "            if not os.path.exists(pathpoints_dir):\n",
    "                os.makedirs(pathpoints_dir)\n",
    "            name = 'pathpoints/path_points '+str(i)+'.yaml'\n",
    "            with open(name, 'w') as file:\n",
    "                documents = yaml.dump(data,file)\n",
    "                documents = yaml.dump(data_1,file)\n",
    "            path_gazebo = []\n",
    "    time_one_epoch = time.time() - start #recording the work time of one epoch\n",
    "    time_tot = time.time() - start_training_time + tot_time_ckpt\n",
    "    ###################\n",
    "    # Evaluate train model and baseline \n",
    "    # in this phase we just solve random instances with the actor and the critic\n",
    "    # compare this soluation if we get any improvment we'll transfer the actor's\n",
    "    # weights into the critic\n",
    "    ###################\n",
    "    # putting the actor in the eval mode\n",
    "    Actor.eval()\n",
    "    \n",
    "    mean_tour_length_actor = 0\n",
    "    mean_tour_length_critic = 0\n",
    "\n",
    "    for step in range(0,B_valLoop):\n",
    "        \n",
    "        # compute tour for model and baseline\n",
    "        X_temp_val = temp.every_point()\n",
    "        X_temp_val = torch.FloatTensor(X_temp_val)\n",
    "        X_val = X_temp_val.repeat(B,1,1)\n",
    "        X_val = X_val.cuda()\n",
    "        mask = torch.zeros(B,size).cuda()\n",
    "        R = 0\n",
    "        reward = 0\n",
    "        Y = X_val.view(B,size,2)\n",
    "        x = torch.zeros(B,2)#Y[:,0,:] #set the first point to x\n",
    "        Y0 = None\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None\n",
    "        Transcontext = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for k in range(size_rec):\n",
    "                #same as the above part\n",
    "                context, Transcontext, output, h, c, _ = Actor(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n",
    "                idx = torch.argmax(output, dim=1)\n",
    "                # prepare for the back propagation of pytorch\n",
    "                reward, Y0,x = rectangle_process(b_temp,f_temp, idx,Y,Y0, mask,k,B)\n",
    "                R += reward\n",
    "        # critic baseline\n",
    "        mask = torch.zeros(B,size).cuda()\n",
    "        C = 0\n",
    "        baseline = 0\n",
    "        \n",
    "        Y = X_val.view(B,size,2)\n",
    "        x = torch.zeros(B,2)#Y[:,0,:] #set the first point to x\n",
    "        \n",
    "        h = None\n",
    "        c = None\n",
    "        context = None\n",
    "        Transcontext = None\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for k in range(size_rec):\n",
    "                #same as the above part\n",
    "                context, Transcontext, output, h, c, _ = Critic(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n",
    "                idx = torch.argmax(output, dim=1)  \n",
    "                # prepare for the back propagation of pytorch\n",
    "                baseline, Y0,x = rectangle_process(b_temp,f_temp, idx,Y,Y0, mask,k,B)\n",
    "                C += baseline\n",
    "\n",
    "        mean_tour_length_actor  += R.mean().item()\n",
    "        mean_tour_length_critic += C.mean().item()\n",
    "\n",
    "    mean_tour_length_actor  =  mean_tour_length_actor  / B_valLoop\n",
    "    mean_tour_length_critic =  mean_tour_length_critic / B_valLoop\n",
    "    # evaluate train model and baseline and update if train model is better\n",
    "\n",
    "    update_baseline = mean_tour_length_actor + TOL < mean_tour_length_critic\n",
    "\n",
    "    print('Avg Actor {} --- Avg Critic {}'.format(mean_tour_length_actor,mean_tour_length_critic))\n",
    "\n",
    "    if update_baseline:\n",
    "        Critic.load_state_dict(Actor.state_dict())\n",
    "        print('My actor is going on the right road Hallelujah :) Updated')\n",
    "    ###################\n",
    "    # Valdiation train model and baseline on 1k random TSP instances\n",
    "    ###################\n",
    "    # erased by daniel due to the 1K tsp is not the scale I want to train  \n",
    "\n",
    "    # For checkpoint\n",
    "    plot_performance_train.append([(epoch+1), mean_tour_length_actor])\n",
    "    plot_performance_baseline.append([(epoch+1), mean_tour_length_critic])\n",
    "    # compute the optimally gap ==> this is interesting because there is no LKH or other optimal algorithms \n",
    "    # for the problem like this rectangle characterized map\n",
    "    mystring_min = 'Epoch: {:d}, epoch time: {:.3f}min, tot time: {:.3f}day, L_actor: {:.3f}, L_critic: {:.3f}, update: {}'.format(\n",
    "        epoch, time_one_epoch/60, time_tot/86400, mean_tour_length_actor, mean_tour_length_critic, update_baseline)\n",
    "\n",
    "    print(mystring_min)\n",
    "    print('Save Checkpoints')\n",
    "\n",
    "    # Saving checkpoint\n",
    "    checkpoint_dir = os.path.join(\"checkpoint\")\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'time': time_one_epoch,\n",
    "        'tot_time': time_tot,\n",
    "        'loss': loss.item(),\n",
    "        'plot_performance_train': plot_performance_train,\n",
    "        'plot_performance_baseline': plot_performance_baseline,\n",
    "        'model_baseline': Critic.state_dict(),\n",
    "        'model_train': Actor.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        },'{}.pkl'.format(checkpoint_dir + \"/checkpoint_\" + time_stamp + \"-n{}\".format(size) + \"-gpu{}\".format(gpu_id)))\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "            \n",
    "                \n",
    "        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def angle(v1):\n",
    "    dx1 = v1[0]\n",
    "    dy1 = v1[1]\n",
    "    angle1 = math.atan2(dy1, dx1)\n",
    "    angle1 = int(angle1 * 180/math.pi)\n",
    "    if angle1 < 0:\n",
    "        angle1 = 360 + angle1\n",
    "    return angle1\n",
    "print(angle([-1,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = [[1,2],[3,4],[5,6],[7,8],[9,10],[11,12]]\n",
    "x = np.array(x)\n",
    "x = np.reshape(x,(2,3,2))\n",
    "for i in x:\n",
    "    print(i)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
